# -*- coding: utf-8 -*-
"""Bản sao của Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kwnKdXVlwyUynX_JUCt05JH_dehzEMOH
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt

! gdown --id 1CDO6doq9J44FrwBpsSAMbP5C7o5H5fL2

! gdown --id 1uhw4GJWqssXPe7fV7op6texwUhHL_eOM

tracks = pd.read_csv('fma-rock-vs-hiphop.csv')
music_features = pd.read_json('echonest-metrics.json',precise_float=True)

tracks.head()

music_features.head()

audio_data=music_features.merge(tracks[['genre_top', 'track_id']], on='track_id')

for index, column in enumerate(audio_data.columns):
    if (index == 0) or (index == len(audio_data.columns) - 1):
        continue
    print(column)
    print(f"min: {audio_data[column].min()}")
    print(f"max: {audio_data[column].max()}")
    print(f"mean: {audio_data[column].mean()}")
    print()

hiphop = audio_data.loc[audio_data['genre_top'] == "Hip-Hop"]

rock = audio_data.loc[audio_data['genre_top'] == "Rock"][:hiphop.shape[0]]

balanced_data = pd.concat([hiphop, rock])

balanced_data[balanced_data.columns[1:9]]

balanced_data.head()

balanced_data.info()

# apply normalization techniques
min_max_normalized = balanced_data.copy()
for index, column in enumerate(min_max_normalized.columns):
    if index == len(min_max_normalized.columns) -1 or index == 0:
        continue
    min_max_normalized[column] = (min_max_normalized[column] - min_max_normalized[column].min()) / (min_max_normalized[column].max() - min_max_normalized[column].min())

min_max_normalized

for index, column in enumerate(min_max_normalized.columns):
    if (index == 0) or (index == len(min_max_normalized.columns) - 1):
        continue
    print(column)
    print(f"min: {min_max_normalized[column].min()}")
    print(f"max: {min_max_normalized[column].max()}")
    print(f"mean: {min_max_normalized[column].mean()}")
    print()

def split_data(data_sets, train_ratio, test_ratio):
    data = data_sets.sample(frac=1)
    total_rows = data.shape[0]
    train_size = int(total_rows * train_ratio)
    train = data[0:train_size]
    test_size = int(total_rows * test_ratio)
    test = data[train_size: train_size + test_size]
    return train, test

def convert_label(Y, label_map):
    label = []
    for y in Y:
        label.append(label_map[y])

    return np.array([label]).T

# Logistic simoid function
def logistic(x):
  return 1/(1 + np.exp(-x))

logistic_vectorize = np.vectorize(logistic)

# Get the vetor for multiplying regulariztion coef with the W
def get_regularization_one_vector(number_of_features: int):
    ones = np.ones((number_of_features, 1))
    ones[0] = 0
    return ones

# Predict ouput given X and W
def predict(X: np.ndarray, W: np.ndarray):
    assert X.shape[1] == W.shape[0] - 1, "Invalid number of features"
    number_of_data_points = X.shape[0]
    X_bar = np.hstack((np.ones((number_of_data_points, 1)), X))
    return logistic_vectorize(X_bar.dot(W))


# Train the model
def train(
    X: np.ndarray,
    Y: np.ndarray,
    initial_W: np.ndarray,
    iterations: int,
    learning_rate: float,
    regular_coeff: float
  ):

    assert X.shape[1] == initial_W.shape[0] - 1, "Invalid number of features"
    assert X.shape[0] == Y.shape[0], "Invalid tranning data"

    number_of_features = initial_W.shape[0]
    number_of_data_points = X.shape[0]
    X_bar = np.hstack((np.ones((number_of_data_points, 1)), X))
    W = initial_W.copy()

    E = []
    for i in range(iterations):
        H = logistic_vectorize(X_bar.dot(W))

        # Calculate loss function with regularzation
        E.append(
            - np.sum(Y * np.log(H) + (1 - Y) * np.log(1 - H)) / number_of_data_points -
            regular_coeff/(2*number_of_data_points) * np.sum(np.square(W))
            )

        # Update W using gradient decent with regularization
        W = W - learning_rate * 1/number_of_data_points * X_bar.T.dot(H - Y)
        - (regular_coeff/number_of_data_points) * W * get_regularization_one_vector(number_of_features)

    return W, E

def calculate_statistics(predicted, actual, positive_label):
    assert len(predicted) == len(actual), 'predicted and actual output have different size'
    tp = 0
    fp = 0
    tn = 0
    fn = 0
    for a, p in zip(predicted, actual):
        if p == positive_label:
            if p == a:
                tp += 1
            else:
                fp += 1
        else:
            if p == a:
                tn += 1
            else:
                fn += 1

    precision = tp / (tp + fp) if (tp + fp) > 0 else 999999
    recall = tp / (tp + fn) if (tp + fn) > 0 else 999999
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 999999
    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 999999

    f_score = 2 * (precision* recall) / (precision + recall) if (precision + recall) > 0 else 999999

    return precision, recall, specificity, accuracy, f_score

def confusion_matrix(
    predicted: list[int],
    actual: list[int],
    labels
  ):
    assert len(predicted) == len(actual), 'predicted and actual output have different size'
    matrix = [ [0]*labels for i in range(labels)]
    for p, a in zip(predicted, actual):
        matrix[p][a] += 1

    return matrix

# Define the ratios
train_ratio = 0.7  # 70% for training
test_ratio = 0.3  # 30% for testing

# Split the data into train, validation, and test sets
train_data, test_data = split_data(min_max_normalized, train_ratio, test_ratio)

X_train = train_data[train_data.columns[1: 9]].to_numpy()
Y_train = convert_label(train_data[train_data.columns[9]].to_numpy(), {
    "Hip-Hop": 1,
    "Rock": 0
})


X_test = test_data[test_data.columns[1: 9]].to_numpy()
Y_test = convert_label(test_data[test_data.columns[9]].to_numpy(), {
    "Hip-Hop": 1,
    "Rock": 0
})
initial_W = np.random.rand(9,1) * 5  - 2.5

iterations = 10000
learning_rate = 0.002
regular_coeff = 0.0001

# After training model
W_trained, E = train(X_train, Y_train, initial_W, iterations, learning_rate, regular_coeff)
predicted = predict(X_train, W_trained)
predicted_label = [1 if p[0] > 0.5 else 0 for p in predicted]

print(W_trained)

# Calculate accuracy on the test set
# Set positive label to Rock
POSITIVE_LABEL = 0
precision, recall, specificity, accuracy, f_score = calculate_statistics(predicted_label, Y_train.T.tolist()[0], POSITIVE_LABEL)

print(f"Precision on test set: {precision * 100:.2f}%")
print(f"Recall on test set: {recall * 100:.2f}%")
print(f"Specificity on test set: {specificity * 100:.2f}%")
print(f"Accuracy on test set: {accuracy * 100:.2f}%")
print(f"F-score on test set: {f_score * 100:.2f}%")


print(confusion_matrix(predicted_label, Y_train.T.tolist()[0], 2))

plt.plot(range(len(E)), E)

t_predicted = predict(X_test, W_trained)
t_predicted_label = [1 if p[0] > 0.5 else 0 for p in t_predicted]

t_precision, t_recall, t_specificity, t_accuracy, t_f_score = calculate_statistics(t_predicted_label, Y_test.T.tolist()[0], POSITIVE_LABEL)

print(f"Precision on test set: {t_precision * 100:.2f}%")
print(f"Recall on test set: {t_recall * 100:.2f}%")
print(f"Specificity on test set: {t_specificity * 100:.2f}%")
print(f"Accuracy on test set: {t_accuracy * 100:.2f}%")
print(f"F-score on test set: {t_f_score * 100:.2f}%")


print(confusion_matrix(t_predicted_label, Y_test.T.tolist()[0], 2))